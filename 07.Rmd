---
output:
  pdf_document: 
    fig_height: 6
    fig_width: 8
  html_document: default
---
# Comparing Several Independent Groups   {#ch7}

Concentrations of volatile organic compounds are measured in shallow ground waters across a several county area. The wells sampled can be classified as being contained in one of seven land-use types:  undeveloped, agricultural, wetlands, low-density residential, high-density residential, commercial, and industrial/transportation.  Do the concentrations of volatiles differ between these types of surface land-use, and if so, how?

Alkalinity, pH, iron concentrations, and biological diversity are measured at low flow for small streams draining areas mined for coal.  Each stream drains either unmined land, land strip-mined and then abandoned, or land strip-mined and then reclaimed.  The streams also drain one of two rock units, a sandstone or a limestone formation.  Do drainages from mined and unmined lands differ in quality?  What affect has reclamation had?  Are there differences in chemical or biological quality due to rock type separate and distinct from the effects due to mining history?

Three methods for field extraction and concentration of an organic chemical are to be compared at numerous wells.  Are there differences among concentrations produced by the extraction processes?  These must be discerned above the well-to-well differences in concentration which contribute considerable noise to the data.

The methods of this chapter can be used to answer questions such as those above.  These methods are extensions of the ones introduced in Chapters 5 and 6, where now more than two groups of data are to be compared.  The classic technique in this situation is analysis of variance.  More robust nonparametric techniques are also presented for the frequent situations where data do not meet the assumptions of analysis of variance.

Suppose a set of continuous data, such as concentration or water levels, is collected.  It is suspected that one or more influences on the magnitude of these data comes from grouped variables, variables whose values are simply "from group X".  Examples include season of the year ("from summer", "winter", etc.), aquifer type, land-use type, and similar groups.  Each observation will be classified into one of these groups.

First consider the effect of only one grouped variable, calling it an **explanatory variable** because it is believed to explain some of the variation in magnitude of the data at hand.  This variable is also called a **factor**.  It consists of a set of k groups, with each data point belonging in one of the k groups.  For example, the data could be calcium concentrations from wells in one of k aquifers, and the objective is to determine whether the calcium concentrations differ among the k aquifers.  Within each group (aquifer) there are nj observations (the sample size of each group is not necessarily the same).  Observation y~ij~ is the ith of n~j~ observations in group j, so that i=1,...n~j~ for the jth of k groups j=1,...k .  The total number of observations N is thus 


\begin{equation}
N = \sum_{j=1}^{k} {n_{j}},    \text{which simplifies to N = k*n}\\
\end{equation}

when the sample size n~j~ = n for all k groups (equal sample sizes).

The tests in this chapter determine if all k groups have the same central value (median or mean, depending on the test), or whether at least one of the groups differs from the others.  When data within each of the groups are normally distributed and possess identical variances, an analysis of variance (ANOVA) can be used.  Analysis of variance is a parametric test, determining whether each group's mean is identical.  When there are only two groups, the ANOVA becomes identical to a t-test.  Thus ANOVA is like a t-test between three or more groups of data, and is restricted by the same types of assumptions as was the t-test.  When every group of data cannot be assumed to be normally distributed or have identical variance, a nonparametric test should be used instead.  The Kruskal-Wallis test is much like a rank-sum test extended to more than two groups.  It compares the medians of groups differentiated by one explanatory variable (one factor).

When the effect of more than one factor is to be evaluated simultaneously, such as both rock type and mining history in one of the examples which began this chapter, the one-way tests can no longer be used.  For data which can be assumed normal, several factors can be tested simultaneously using multi-factor analysis of variance.   However, the requirements of normality and equal variance now apply to data grouped by each unique combination of factors.    This becomes quite restrictive and is rarely met in practice.  Therefore nonparametric alternatives are also presented.

The following sections begin with tests for differences due to one factor.  Subsequent sections discuss tests for effects due to more than one factor.   All of these have as their null hypothesis that each group median (or mean) is identical, with the alternative that at least one is different.  However, when the null hypothesis is rejected, these tests do not tell which group or groups are different!  Therefore sections also follow on multiple comparison tests -- tests performed after the ANOVA or Kruskal-Wallis null hypothesis has been rejected, for determining which groups differ from others.  A final section on graphical display of results finishes the chapter.

## Tests for Differences Due to One Factor
### The Kruskal-Wallis Test
The Kruskal-Wallis test, like other nonparametric tests, may be computed by an exact method used for small sample sizes, by a large-sample approximation (a chi-square approximation) available on statistical packages, and by ranking the data and performing a parametric test on the ranks.   Tables for the exact method give p-values which are exactly correct.  The other two methods produce approximate p-values that are only valid when sample sizes are large, but do not require special tables.  Tables of exact p-values for all sample sizes would be huge, as there are many possible combinations of numbers of groups and sample sizes per group.  Fortunately, large sample approximations for all but the smallest sample sizes are very close to their true (exact) values.  Thus exact computations are rarely required. All three versions have the same objective, as stated by their null and alternate hypotheses.

#### Null and alternate hypotheses
In its most general form, the Kruskal-Wallis test has the following null and alternate hypotheses:

            H 0: All of the k groups of data have identical distributions, versus
            H 1: At least one group differs in its distribution

No assumptions are required about the shape(s) of the distributions.  They may be normal, lognormal, or anything else.  If the alternate hypothesis is true, they may have different distributional shapes.  In this form, the only interest in the data is to determine whether all groups are identical, or whether some tend to produce observations different in value than the others.  This difference is not attributed solely to a difference in median, though that is one possibility.  Thus the Kruskal-Wallis test, like the rank-sum test, may be used to determine the general equivalence of groups of data.   
In practice, the test is usually performed for a more specific purpose \-- to determine whether all groups have the same median, or whether at least one median is different.  This form requires that all other characteristics of the data distributions, such as spread or skewness, are identical \-- though not necessarily in the original units.  Any data for which a monotonic transformation, such as in the ladder of powers, produces similar spreads and skewness are also valid.  This parallels the rank-sum test (see Chapter 5).  As a test for difference in medians, the KruskalWallis null and alternate hypotheses are:

         H 0: The medians of the k groups are identical,   
         H 1: At least one median differs from the others. (a 2-sided test).
         
As with the rank-sum test, the Kruskal-Wallis test statistic and p-value computed for data that are transformed using any monotonic transformation are identical to the test statiistic and pvalue using the original units.  Thus there is little incentive to search for transformations (to normality or otherwise) \-- the test is applicable in many situations.

#### Computation of the exact test
The exact form of the Kruskal-Wallis test is required when comparing 3 groups with sample sizes of 5 or less per group, or with 4 or more groups of size 4 or less per group (Lehmann, 1975).  For larger sample sizes the large-sample approximation is sufficiently accurate.  As there are few instances where sample sizes are small enough to warrant using the exact test, exact tables for the Kruskal-Wallis test are not included in this book.  Refer to either Conover (1980) or Lehmann (1975) for those tables. 
Should the exact test be required, compute the exact test statistic K as shown in the large sample approximation of the following section.  K is computed identically for both the exact form or large sample approximation.  When ties occur, the large sample approximation must be used.

#### The large-sample approximation
To compute the test, the data are ranked from smallest to largest, from 1 to N.  At this point the original values are no longer used; their ranks are used to compute the test statistic.  If the null hypothesis is true, the average rank for each group should be similar, and also be close to the overall average rank for all N data.  When the alternative hypothesis is true, the average rank for some of the groups will differ from others, reflecting the difference in magnitude of its observations.  Some of the average group ranks will then be significantly higher than the overall average rank for all N data, and some will be lower.  The test statistic K uses the squares of the differences between the average group ranks and the overall average rank, to determine if groups differ in magnitude.  K will equal 0 if all groups have identical average ranks, and will be positive if group ranks are different.  The distribution of K when the null hypothesis is true can be approximated quite well by a chi-square distribution with k−1 degrees of freedom.

The degrees of freedom is a measure of the number of independent pieces of information used to construct the test statistic.  If all data are divided by the overall group mean to standardize the data set, then when any k−1 average group ranks are known, the final (kth) average rank can be computed from the others as

\begin{equation}
\overline{R}_{k} = \frac{N} {n_{k}} \bullet [1 - \sum_{j=1}^{k-1} \frac{n_{j}} {N} \overline{R}_{j}]
\end{equation}

Therefore there are actually only k−1 independent pieces of information represented by the k average group ranks.  From these the kth average rank is fixed.

```{r fig-T_7_01, echo = FALSE, fig.align='center', fig.cap=""}
knitr::include_graphics("figures/T_7_01.png")

```

<u>Example 1</u>.  
Fecal coliforms, in organisms per 100 ml, were measured in the Illinois River from 1971 to 1976 (@lin1980coliforms).  A small subset of those data are presented here.  Do all four seasons exhibit similar values, or do one or more seasons differ?  Boxplots for the four seasons are shown in figure \@ref(fig:fig-7-1).

```{r fig-T_7_1, echo = FALSE, fig.align='center', fig.cap=" Selected fecal coliform data (from @lin1980coliforms).  [counts in organisms per 100 ml] "}
knitr::include_graphics("figures/T_7_1.png")
```


```{r fig-7-1, echo = FALSE, fig.cap = "   Boxplots of Fecal Coliform Data from the Illinois River  ", fig.align="center"}
knitr::include_graphics("figures/7_1.png")
```

Should a parametric or nonparametric test be performed on these data?  If even one of the four groups exhibits non-normality, the assumptions of parametric analysis of variance are violated.  The consequences of this violation is an inability to detect differences which are truly present -- a lack of power.  The PPCC test for normality rejects normality at α =0.05 for two of the seasons, summer and spring (table 7.1).  Outliers and skewness for the fall samples also argue for non-normality.  Based solely on the skewness and outliers evident in the boxplot, a nonparametric test should be used on these data.

Computation of the Kruskal-Wallis test is shown in table \@ref(fig:fig-T_7_2).  This is compared to a table of the chi-square distribution available in many statistics texts, such as Iman and Conover (1983).  We conclude that there is not enough evidence in these data to reject the assumption that fecal coliform counts are distributed similarly in all four seasons.

Table 7.2.  Kruskal-Wallis test for the fecal coliform data
```{r, fig-T_7_2, echo = FALSE, fig.align="center"}
knitr::include_graphics("figures/T_7_2.png")
```


#### The rank transform approximation 
The rank transform approximation to the Kruskal-Wallis test is computed by performing a onefactor analysis of variance on the ranks R~ij~.  This approximation compares the mean rank within each group to the overall mean rank, using an F-distribution for the approximation of the distribution of K.  The F and chi-square approximations will result in very similar p-values.  The rank transform method should properly be called an "analysis of variance on the ranks".  

For the example 1 data, the rank transform approximation results in a p-value of 0.47, essentially identical to that for the large sample approximation.  Detailed computations are shown following the discussion of ANOVA in the next section. 

####  Analysis of Variance (One Factor)
Analysis of variance is the parametric equivalent to the Kruskal-Wallis test.  It compares the mean values of each group with the overall mean for the entire data set.  If the group means are dissimilar, some of them will differ from the overall mean, as in figure \@ref(fig:fig-7-2).  If the group means are similar, they will also be similar to the overall mean, as in figure \@ref(fig:fig-7-3). 

```{r fig-7-2, echo = FALSE, fig.cap = "   Hypothetical data for three groups.  Treatment mean square > Error mean square.  ", fig.align="center"}
knitr::include_graphics("figures/7_2.png")
```

Why should a test of differences between means be named an analysis of variance?  In order to determine if the differences between group means (the signal) can be seen above the variation within groups (the noise), the total noise in the data as measured by the total sum of squares is split into two parts:  

**Total sum of squares = Treatment sum of squares + Error sum of squares**  
(overall variation) = (group means − overall mean) + (variation within groups)  

\begin{equation}
\sum_{j=1}^{k}\sum_{i=1}^{{n}_{j}}(y_{ij}-\overline{y})^{2} = \sum_{j=1}^{k} {n}_{j}(\overline{y}_{j}-\overline{y})^{2} + \sum_{j=1}^{k}\sum_{i=1}^{{n}_{j}}(y_{ij}-\overline{y})^{2}
\end{equation}

If the total sum of squares is divided by N−1, where N is the total number of observations, it equals the variance of the y~ij~'s.  Thus ANOVA partitions the variance of the data into two parts, one measuring the signal and the other the noise.  These parts are then compared to determine if the means are significantly different. 


#### Null and alternate hypotheses 
The null and alternate hypotheses for the analysis of variance are:   

     H~0~: the k group means are identical  µ~1~ = µ~2~ = ...= µ~k~ .   
     H~1~: at least one mean is different.  
     
```{r fig-7-3, echo = FALSE, fig.cap = "   Hypothetical data for three groups.  Treatment mean square ≅ Error mean square. ", fig.align="center"}
knitr::include_graphics("figures/7_3.png")
``` 

#### Assumptions of the test 
If ANOVA is performed on two groups, the F statistic which results will equal the square of the two-sample t-test statistic F=t^2^, and will have the same p-value.  It is not surprising, then, that the same assumptions apply to both tests: 

1. All samples are random samples from their respective populations.    
2. All samples are independent of one another.  
3. Departures from the group mean (y~ij~ − y ~j~) are normally distributed for all j groups.   
4. All groups have equal population variance σ2 estimated for each group by s~j~^2^


\begin{equation}
{s}_{j}^{2} = \frac {\sum_{i=1}^{{n}_{j}} (y_{ij}-\overline{y}_{j})^{2}} {{n}_{j}-1}
\end{equation}


Violation of either the normality or constant variance assumption results in a loss of ability to see differences between means (a loss of power).  The analysis of variance suffers from the same five problems as did the t-test:  1) lack of power when applied to non-normal data, 2) dependence on an additive model, 3) lack of applicability for censored data, 4) assumption that the mean is a good measure of central tendency for skewed data, and 5) difficulty in assessing whether the normality and equality of variance assumptions are valid for small sample sizes.  See Chapter \@ref(ch5) for a detailed discussion of these problems. 

Difficulties arise when using prior tests of normality to "prove" non-normality before allowing use of the nonparametric Kruskal-Wallis test.  Small samples sizes may inhibit detecting nonnormality, as mentioned above.  Second, transformations must be done on more than two groups of data.  It is usually quite difficult to find a single transformation which when applied to all groups will result in each becoming normal with constant variance.  Even the best transformation based on sample data may not alleviate the power loss inherent when the assumptions of ANOVA are violated.  Finally, if all groups are actually from a normal distribution, one or more may be "proven" non-normal simply by chance (there is an α% chance for each group).  Thus the results of testing for normality can be quite inconclusive prior to performing ANOVA.  The value of nonparametric approaches here is that they are relatively powerful for a wide range of situations.    


#### Computation 














## Tests for the Effects of More Than One Factor
It is quite common that more than one factor is suspected to be influencing the magnitudes of observations.  In these situations it is desirable to measure the influence of all factors simultaneously.  Sequential one-factor tests are an inadequate alternative to a single multi-factor test.  Even when only one factor is actually influencing the data and a one-way ANOVA for that factor soundly rejects H~0~, a second one-way test for a related factor may erroneously reject H~0~ simply due to the association between the two factors.  The test for the second factor should remove the effect of the first before establishing that the second has any influence.  By evaluating all factors simultaneously, the influence of one can be measured while compensating for the others.  This is the objective of a multi-factor analysis of variance, and of the nonparametric analogue.

### Nonparametric Multi-Factor Tests 
For two-factor and more complex ANOVA's where the data within one or more treatment groups are not normally distributed and may not have equal variances, there are two possible approaches for analysis.  The first is a class of tests which include the Kruskal-Wallis and Friedman tests as simpler cases.  These tests, described by Groggel and Skillings (1986), do not allow for interactions between factors.  The tests reformat multiple factors into two factors, one the factor being tested, and the other the collection of all other treatment groups for all remaining factors.  The data are then ranked within treatment groups for analysis, much as in a Friedman test.  The reader is referred to their paper for more detail.

The second procedure is a rank transformation test (Conover and Iman, 1981).  All data are ranked from 1 to N, and an ANOVA computed on the ranks.  This procedure is far more robust to departures from the assumptions of normality and constant variance than is an ANOVA on the original data.  The rank transformation produces values which are much closer to meeting the two critical assumptions than are the original values themselves.  The tests determine whether the mean rank differs between treatment groups, rather than the mean.  The mean rank is interpreted as an estimate of the median.  Multiple comparison procedures on the ranks can then differentiate which groups differ from others.

Examples of the computation and performance of these rank transformation tests will be delayed until after discussion of parametric factorial ANOVA

###  Multi-Factor Analysis of Variance -- Factorial ANOVA
The effects of two or more factors may be simultaneously evaluated using a factorial ANOVA design.  A factorial ANOVA occurs when none of the factors is a subset of the others.  If subsetted factors do occur, the design includes "nested" factors and the equations for computing the F test statistics will differ from those here (nested ANOVA is briefly introduced in a later section).  A two-factor ANOVA will be fully described -- more than two factors can be incorporated, but are beyond the scope of this book.  See Neter, Wasserman and Kutner (1985) for more detail on higher-way  and nested analysis of variance.

For a two-factor ANOVA, the influences of two explanatory variables are simultaneously tested.  The first page of this chapter presented a two-factor ANOVA, the determination of chemical concentrations among basins at low flow.  The objective was to determine whether concentrations differed as a function of mining history (whether or not each basin was mined, and if so whether it was reclaimed) and of rock type.

####   Null and alternate hypotheses
Call the two factors A and B.  There are i=1,...a ≥ 2 categories of factor A, and  j=1,...b ≥ 2 categories of factor B.  Treatment groups are defined as all the possible combinations of factors A and B, so there are a•b treatment groups.  Within each treatment group there are n~ij~ observations.  The test determines whether mean concentrations are identical among all the a•b treatment groups, or whether at least one differs.

H~0~ :  all a•b treatment group means µ~ij~ are equal µ~11~= µ~12~ = ...= µ~ab~  
H~1~ :  at least one µ~ij~ differs from the rest. 

The magnitude of any observation yijk can be affected by several possible influences:

\begin{equation}
Y_{ijk} =  µ + αi + β_{j} + αβ_{ij} + ε_{ijk}, \text {where}\\  
\end{equation}

<center> > α~i~ = influence of the ith category of A  
      β~j~ = influence of the jth category of B  
         αβ~ij~ = interaction effect between A and B beyond those of α~i~ and β~j~  
             separately for the ijth treatment group, and  
    ε~ijk~ = residual error, the difference between the kth observation (k=1,...n~ij~) and the treatment group mean µ~ij~.   
</center>  


The null hypothesis states that treatment group means µij all equal the overall mean µ.  Therefore αi βj and αβ~ij~ all equal 0 \-- there are no effects due to any of the factors or to their interaction.  If any one of α~i~, β~j~, or αβ~ij~ are nonzero, the null hypothesis is rejected, and at least one treatment group evidences a difference in its mean. 

#### Interaction between factors  

If αβ~ij~ = 0 in the equation above, there is no interaction present.  Without interaction, the effect of factor B is identical for all groups of factor A, and the effect of factor A is identical for all groups of factor B.  Suppose there are 3 groups of factor A (a1, a2, and a3) and 2 groups of factor B (b1 and b2), resulting in six treatment groups overall.  Lack of interaction can be visualized by plotting the means for all treatment groups as in figure 7.4.  The parallelism of the lines shows that no interaction is present.  The effect of A going from a1 to a2 to a3 is identical regardless of which B group is involved.  The increase going from b1 to b2 for factor B is identical for every group of factor A.

When interaction is present (αβij ≠ 0) the treatment group means are not determined solely by the additive effects of factors A and B alone.  Some of the groups will have mean values larger or smaller than those expected just from the results of the individual factors.  The effect of factor A can no longer be discussed without reference to which group of factor B is  of interest, and the effect of factor B can likewise not be stated apart from a knowledge of the group of factor A.  In a plot of the treatment group means, the lines are no longer parallel (figure 7.5).  The pattern of differences going from a1 to a2 to a3 depends on which group of factor B is of interest, and likewise for the differences between b1 and b2 -- the pattern differs for the three A groups.


```{r fig-7-4, echo = FALSE, fig.cap = "  Six treatment group means with no interaction present ", fig.align="center"}
knitr::include_graphics("figures/7_4.png")
```

```{r fig-7-5, echo = FALSE, fig.cap = "   Six treatment group means with interaction present ", fig.align="center"}
knitr::include_graphics("figures/7_5.png")
```

Interaction can result from a synergistic or antagonistic effect.  As an example, fish may not die instream due only to higher water temperatures, or to slightly higher copper concentrations, but combine the two and the result could be deadly.  This type of interrelation between factors results in a significant interaction effect.  For k factors there are (k−1) possible interaction terms between the factors.  Unless it is known ahead of time that interactions are not possible, interaction terms should always be included and tested for in multi-factor ANOVA models. 

#### Assumptions for factorial ANOV

Assumptions are the same as for a one-way ANOVA.  Departures from each treatment group mean µ~ij~ (every combination of factors A and B) are assumed normally distributed with identical variance.  This is a consequence of the ε~ij~, which are normally distributed and of variance σ2, being randomly distributed among the treatment groups.  The normality and constant variance assumptions can be checked by inspecting boxplots of the data for each treatment group.

#### Computation
The influences of factors A, B, and their interaction are evaluated separately by again partitioning the total sums of squares into component parts due to each factor.  After dividing by their respective degrees of freedom, the mean squares for factors A, B, and interaction are produced.  As with a one-way ANOVA, these are compared to the error mean square (MSE) using F-tests to determine their significance.

sum of Squares  
The equations for the sums of squares for factor A (SSA), factor B (SSB), interaction (SSI), and error, assuming constant sample size n per treatment group, are:

\begin{equation}
SSA = \sum^{a} \frac{(\sum^{b}\sum^{n}y)^{2}} {bn} - \frac{(\sum^{a}\sum^{b}\sum^{n}y)^{2}} {abn}    µ_{i}-µ\\
SSB = \sum^{b} \frac{(\sum^{a}\sum^{n}y)^{2}} {an} - \frac{(\sum^{a}\sum^{b}\sum^{n}y)^{2}} {abn}    µ_{j}-µ\\  
SSI  =    Total SS − SSA − SSB − SSE                                           µ_{ij} − (µ_{i} + µ_{j} ) + µ\\
SSE = \sum^{a}\sum^{b}\sum^{n} (y)^{2} - \sum^{a}\sum^{b} \frac{(\sum^{n}y)^{2}} {n}  y_{ijk}-µ_{ij}\\  
Total SS = \sum^{a}\sum^{b}\sum^{n} (y)^{2}- \frac{(\sum^{a}\sum^{b}\sum^{n}y)^{2}} {abn}   y_{ijk}-µ\\ 

\end{equation}

<u>Mean Squares and the F-test </u>

Dividing the sums of squares by their degrees of freedom produces the mean squares for factors A, B, interaction, and error as in the ANOVA table below.  If H~0~ is true and α~i~, β~j~, and αβ~ij~ all equal 0, all variation is simply around the overall mean µ.  The MSA, MSB, and MSI will then all be measures of the error variance, as is the MSE, and all three F-tests will have ratios not far from 1.  However when H~1~ is true, at least one of the mean squares in the numerators should be larger than the MSE, and the resulting F-ratio will be larger than the appropriate quantile of the F distribution.  When F is large, H~0~ can be rejected, and that influence be considered to significantly affect the magnitudes of the data at a level of risk equal to α.

The two-factor ANOVA table is as follows when there is an equal number of observations for each treatment (all n~ij~ = n).


|   Source    |     df          | SS |   MS         |  F          | p-value
|-------------|---------------  |----|--------------|-------------|---------
|Factor A     |(a-1)            | SSA|SSA/(a-1)     | MSA/MSE     |
|Factor B     |(b-1)            |SSB |SSB/(b-1)     | MSB/MSE     |
|Interaction  |(a-1)(b-1)       |SSI |SSI/(a-1)(b-1)| MSI/MSE     |
|Error        |<u> ab(n-1)</u>  |SSE |SSE/[ab(n-1)] |             |
|Total        | abn-1           |Total SS|          |             |



```{r fig-T_7_02, echo =FALSE, fig.align='center', fig.cap=""}
knitr::include_graphics("figures/T_7_02.png")

```

<u>Example 2 </u>
Iron concentrations were measured at low flow in numerous small streams in the coal-producing areas of eastern Ohio @helsel1983mine. Each stream drains either an unmined area, a reclaimed coal mine, or an abandoned coal mine. Each site is also underlain by either a sandstone or limestone formation.  Are iron concentrations influenced by upstream mining history, by the underlying rock type, or by both?

There are several scenarios which would cause H0 to be rejected.  Factor A (say mining history) could be significant (α~i~≠ 0), but factor B insignificant.  Or factor B (rock type) could be significant (βj≠ 0), but not A.  Both factors could be significant (α~i~, β~j~ ≠ 0).  Both factors could be significant, plus an additional interaction effect because one or more treatment groups (say unreclaimed sandstone basins) exhibited much different iron concentrations than those expected from either influence alone (α~i~, β~j~, αβ~ij~ ≠ 0).  Finally, both factor A and B could be not significant (α~i~, β~j~ = 0) but concentrations be elevated for one specific treatment group (αβ~ij~ ≠ 0).  This would be interpreted as no overall mining  or rock type effect, but one combination of mining history and rock type would have differing mean concentrations. 

Boxplots for a subset of the iron concentration data from @helsel1983mine are presented in \@ref(fig:fig-7-6).  Note the skewness, as well as the differences in variance as depicted by differing box heights.  A random subset was taken in order to produce equal sample sizes per treatment group, yet preserving the essential data characteristics.  The subset data are listed in **Appendix C5**.  In the section **7.2.2.5**, analysis of unequal sample sizes per treatment group will be presented and the entire iron data set analyzed.  

There are six treatment groups, combining the three possible mining histories (unmined, abandoned mine, and reclaimed mine) and the two possible rock types (sandstone and limestone).  An analysis of variance conducted on this subset which has n=13 observations per treatment group produced the following ANOVA table.  Tested was the effect of mining history alone, rock type alone, and their interaction (Mine\*Rock).  A*B is a common abbreviation for the interaction between A and B.

ANOVA table for the subset of iron data

|   Source    | df       |   SS         | MS   |   F     | p-value
|-------------|---       |-----------   |------|---------|--------
|Rock         |1         | 15411        |15411 |2.38     | 0.127
|Mine         |2         | 32282        |16141 |2.49     | 0.090
|Rock*Mine    |2         | 25869        |12934 |2.00     | 0.143
|<u>Error</u> |<u>72</u> |<u> 466238</u>|6476  |
|Total        |77        | 539801       


None of the three possible influences is significant at the α = 0.05 level, as their  p-values are all larger than 0.05.  However, the gross violation of the test's assumptions of normality and equal variance shown in the boxplots must be considered.  Perhaps the failure to reject H~0~ is due not to a lack of an influence evidenced in the data, but of the parametric test's lack of power to detect these influences because of the violation of test assumptions.  To determine whether this is so, the equivalent rank transformation test is performed.


```{r fig-7-6, echo = FALSE, fig.align='center', fig.cap=" A subset of the iron concentrations at low flow from @helsel1983mine"}
knitr::include_graphics("figures/7_6.png")

```

To compute the rank transformation test, the data are ranked from smallest to largest, 1 to
n=78. An analysis of variance is then performed on the ranks of the data. The ANOVA table is below, while a boxplot of data ranks is shown in figure \@ref(fig:fig-7-7).

ANOVA table for the ranks of the subset of iron data

|   Source    | df       |   SS         | MS    |   F     | p-value
|-------------|---------:|-------------:|------:|---------|--------
|Rock         |1         | 4121.7       |4121.7|13.38     | 0.000
|Mine         |2         | 10933.9      |5467.0 |17.74    | 0.000
|Rock*Mine    |2         | 2286.2       |1143.1 |3.71     | 0.029
|<u>Error</u> |<u>72</u> |<u>22187.2</u>|308.2  |
|Total        |77        | 39529.0       

Results for the rank transformation tests are startlingly different than those for the parametric ANOVA. All three influences, mining history, rock type, and their interaction, are significant at α = 0.05. Gross violations of the assumptions of ANOVA by these data have clearly inhibited the parametric test from detecting the influences of these factors. The rejection of H0 for the rank test indicates that the median iron concentrations differ between treatment groups. Mean concentrations will be distorted by the skewness and outliers present in most of the treatment groups.

Analysis of variance on data ranks is an "asymptotically distribution-free" technique. That is, for sufficiently large sample sizes it tests hypotheses which do not require the assumption of data normality. For the cases where equivalent, truly nonparametric techniques exist such as the Kruskal-Wallis and Friedman tests, the rank transformation procedures have been shown to be large-sample approximations to the test statistics for those techniques. Where no equivalent nonparametric methods have yet been developed such as for the two-way design, rank transformation results in tests which are more robust to non-normality, and resistant to outliers and non-constant variance, than is ANOVA without the transformation.


```{r fig-7-7, echo = FALSE, fig.align='center', fig.cap=" Boxplots of the ranks of the iron data shown in Figure 7.6 "} 
knitr::include_graphics("figures/7_7.png")

```

A third option for analysis of the two-way design is ANOVA on data transformed by a power
transformation. The purpose of the power transformation is to produce a more nearly-normal and constant variance data set. As water resources data are usually positively skewed, the log transformation is often employed. Using logarithms for ANOVA implies that the influences of each factor are multiplicative in the original units, as the influences of the logarithms are additive. The primary difficulty in using a power transformation is in producing a normally distributed error structure for every treatment group. Groups which are skewed may be greatly aided by a transformation, but be side-by-side with a group which was symmetric in the original units, and is now asymmetric after transformation! Boxplots for each treatment group should be inspected prior to performing the ANOVA to determine if each group is at least symmetric. When only some of the treatment groups exhibit symmetry, much less normality, concerns over the power of the procedure remain. F tests which appear to be not significant are always suspect.

In figure \@ref(fig:fig-7-8), boxplots of the base 10 logarithms of the low-flow iron concentrations are presented. Most of the treatment groups still remain distinctly right-skewed even after the transformation, while the unmined limestone group appears less symmetric following transformation! There is nothing magic in the log transformation -- any other transformation going down the ladder of powers might also remedy positive skewness. It may also alter a symmetric group into one that is left-skewed. The search for a transformation which results in all groups being symmetric is often fruitless. In addition, the "best" power transformation will likely change going from one data set to another, one location to another, and one time period to another. In comparison, the rank transformation has simplicity, comparability among locations and time periods, and general validity as being asymptotically distribution-free. When the assumptions of normality and constant variance are questionable, the rank transformation is the most generally appropriate
alternative.

```{r fig-7-8, echo = FALSE, fig.align='center', fig.cap=" Boxplots of the base 10 logarithms of the iron data shown in Figure 7.6 "} 
knitr::include_graphics("figures/7_8.png")

```

#### Unequal sample sizes
Equations presented in the previous section are appropriate only when the number of data per treatment group is identical for each group. This is also called a "balanced" design. Computations for unequal sample sizes ("unbalanced" designs) are more complex. Smaller statistics software packages often encode tests valid only for balanced designs, though that is not always obvious from their output. Yet water resources data rarely involve situations when all sample sizes are equal. Sample bottles are broken, floods disrupt the schedule, etc. When data are unbalanced, the sums of squares for the above equations no longer test.

H~0~: μ~1~ = μ~2~ = ... = μ~k~  
           
but test instead an hypothesis involving weighted group means, where the weights are a function of treatment group sample sizes. This is of little use to the practitioner. Some software will output the (useless and incorrect) results valid only for equal sample sizes even when unbalanced data are provided as input, with no warnings of their invalidity. Be sure that when unequal sample sizes occur, tests which can incorporate them are performed.


To perform ANOVA on unbalanced data, a regression approach is necessary. This is done on larger statistical packages such as Minitab or SAS. SAS's "type I" sums of squares (called "sequential sums of squares" by Minitab) are valid only for balanced cases, but SAS's "type III" sums of squares (Minitab's "adjusted sums of squares") are valid for unbalanced cases as well. Unbalanced ANOVAs are computed in the same fashion as nested F-tests for comparing regression models in analysis of covariance, discussed in Chapter \@ref(ch11). Because the equations for the sums of squares are "adjusted" for unequal sample sizes, they do not sum to the total sum of squares as for balanced ANOVA. See @neter1985applied for more detail on the use of regression models for performing unbalanced ANOVA.

<u>Example 2, continued</u>

The complete 241 observations (Appendix C6) from @helsel1983mine are analyzed with an unbalanced ANOVA. Boxplots for the six treatment groups are shown in figure \@ref(fig:fig-7-9). They are quite similar to those in \@ref(fig:fig-7-6), showing that the subsets adequately represented all the data. An ANOVA table for the complete iron data set is as follows. Note that the sums of squares do not add together to equal the total sum of squares for this unbalanced ANOVA. Results for these data would be incorrect if performed by software capable only of balanced ANOVA. Conclusions reached (do not reject for all tests) agree with those previously given for ANOVA on the data subset.


ANOVA table for the complete (unbalanced) iron data

|   Source    | df       |   SS         | MS    |   F     | p-value
|-------------|---------:|-------------:|------:|--------:|--------:
|Rock         |1         | 71409        |71409  |0.51     | 0.476
|Mine         |2         | 262321       |131160 |0.93     | 0.394
|Rock*Mine    |2         | 178520       |89260  |0.64     | 0.530
|<u>Error</u> |<u>235</u>| 32978056     |140332 |
|Total        |240       | 34062640       


```{r fig-7-9, echo = FALSE, fig.align='center', fig.cap=" Iron concentrations at low flow from @helsel1983mine "} 
knitr::include_graphics("figures/7_9.png")

```

#### Fixed and random factors
An additional requirement for the F tests previously given is that both factors are fixed. With a fixed factor, the inferences to be made from the results extend only to the treatment groups under study. For example, the influences of unmined, abandoned, and reclaimed mining histories were previously compared. Differences in resulting chemical concentrations between these three specific mining histories are of interest, and hence this is a fixed factor. A random factor would result from a random selection of several groups out of a larger possible set to represent the overall factor. Inferences from the test results would be extended beyond the specific groups being tested to the generic factor itself. Thus there is little or no interest in attributing test results to a specific individual group, but only in ascertaining a generic effect due to that factor.  

As an example, suppose soil concentrations of a trace metal are to be compared between three particle size fractions all across the state, to determine which of the three fractions is most appropriate as a reconnaissance medium. Particle size is a fixed effect -- there is interest in those specific sizes. However, there is only enough funding to sample sparsely if done all across the state, so instead a random factor is incorporated to determine whether spatial differences occur. Several counties are selected at random, and intensive sampling occurs within those counties. No sampling is done outside of those counties. The investigator will determine not only which size fraction is best, but whether this is consistent among the counties (the random effect), which by inference is extended to the entire state. There is no specific interest in the counties selected, but only as they represent spatial variability.  

If every factor were random, F tests would use the mean squares for interaction as denominators rather than the mean square for error. If a mix of random and fixed factors occurs (called a "mixed effects" design) as in the example above, there would be a mixture of mean squares used
as denominators. In general the fixed factors in the design use the interaction mean squares as denominators, and the random factors the error mean square, the reverse of what one might intuitively expect! However, the structure of mixed effects F tests can get much more complicated, especially for more than two factors, and texts such as  @neter1985applied or @sokal1981biometry should be consulted for the correct setup of F tests when random factors are present. Note that computer software uses the MSE in the denominator unless otherwise specified, and thus assumes that all factors are fixed. Therefore F tests automatically produced will not be correct when random factors are present, and the correct F ratio must be specifically requested and computed.

## Blocking -- The Extension of Matched-Pair Tests
In Chapter \@ref(ch6), tests for differences between matched-pairs of observations were discussed. Each pair of observations had one value in each of two groups, such as "before" versus "after". The advantage of this type of design is that it "blocks out" the differences from one matched-pair to another that is contributing unwanted noise. Such noise may mask the differences between the two groups (the treatment effect being tested) unless matched-pairs are used.

Similar matching schemes can be extended to test more than two treatment groups. Background noise is eliminated by applying the treatment to blocks (rather than pairs) of similar or identical individuals. Only one observation is usually available for each combination of treatment and block. This is called a "randomized complete block design", and is a common design in the statistical literature.  


The third example at the beginning of this chapter, detecting differences between three extraction methods used at numerous wells, is an example of this design. The treatment effect is the extraction method, of which there are three types (three groups). The blocking effect is the well location; the well-to-well differences are to be "blocked out". One sample is analyzed for each extraction method at each well.

Four methods for analysis of a randomized complete block design will be presented. Each of them attempts to measure the same influences. To do this, each observation yij is broken down into the effects of four influences:

\begin{equation}
y_{ij} =  µ + α_{j} + β_{i} + ε_{ij},  
\end{equation}

<center> > y~ij~ is the individual observation in block i and group j;   
      µ is the overall mean or median (over all groups),   
         α~j~ is the "jth group effect", j=1,k   
          β~i~   is the "ith block effect", i=1,n     
    ε~ij~ is the residual or "error" between the individual observation and the   
combined group and block effects
</center>  


Median polish provides resistant estimates of the overall median, of group effects and block effects. It is an exploratory technique, not an hypothesis test procedure. Related graphical tools determine whether the two effects are additive or not, and whether the ε~ij~ are normal, as assumed by an ANOVA. If not, a transformation should be employed to achieve additivity andnormality before an ANOVA is performed. The Friedman and median aligned ranks tests are nonparametric alternatives for testing whether the treatment effect is significant in the presence of blocking.   

### Median Polish
Median polish (@hoaglin_understanding_1983) is an iterative process which provides a resistant estimate m of the overall median μ, as well as estimates aj of the group effects α~j~ and b~i~ of the block effects β~i~. Its usefulness lies in its resistance to effects of outliers. The polishing is begun by subtracting the medians of each row from the data table, leaving the residuals. The median of these row medians is then computed as the first estimate of the overall median, and subtracted from the row medians. The row medians are now the first estimates of the row effects. Then the median of each column is subtracted from the residual data table and set aside. The median of the column medians is subtracted from the column medians, and added to the overall median.
The column medians now become the first estimates of the column effects. The entire process is repeated a second time, producing an estimated overall median m, row and column departures from the overall median (estimates a~j~ and b~i~), and a data table of residuals e~ij~ estimating the ε~ij~.

<u>Example 3</u>  
Mercury concentrations were measured in periphyton at six stations along the South River, Virginia, above and below a large mercury contamination site (@Walpole_probability_1985). Measurements were made on six different dates. Of interest is whether the six stations differ in mercury concentration. Is this a one-way ANOVA setup? No, because there may be
differences among the six dates -- the periphyton may not take up mercury as quickly during some seasons as others, etc. Differences caused by sampling on six different dates are unwanted noise which should be blocked out, hence date is a blocking effect. The data are presented in table 7.3, and boxplots by station in figure \@ref(fig:fig-7-10). There appears to be a strong increase in mercury concentration going downstream from station 1 to station 6, reflecting an input of mercury along the way. 


Table-7.3 Mercury Concentrations in Periphyton (@Walpole_probability_1985)


|   Station:  | 1          |  2         | 3    |   4     | 5   |  6
|-------------|---------:  |-----------:|-----:|--------:|----:|----:
|<u>Date</u>  |            |            |      |         |     | 
|             |            |            |      |         |     |
|1            |0.45        | 3.24       |1.33  |2.04     | 3.93| 5.93
|2            |0.10        | 0.10       |0.99  |4.31     | 9.92| 6.49
|3            |0.25        | 0.25       |1.65  |3.13     | 7.39| 4.43
|4            |0.09        | 0.06       |0.92  |3.66     | 7.88| 6.24
|5            |0.15        | 0.16       |2.17  |3.50     | 8.82| 5.39
|6            |0.17        | 0.39       |4.30  |2.91     | 5.50| 4.29


```{r fig-7-10, echo = FALSE, fig.align='center', fig.cap=" Periphyton Mercury Upstream (1) to Downstream (6) of Input to River "} 
knitr::include_graphics("figures/7_10.png")

```


The first step in median polish is to compute the median of each row (date), and subtract it from that row's data. The residuals remain in the table.   



|   Station:  | 1     |  2    | 3     |   4   | 5     |  6   |row med  
|-------------|----- :|------:|------:|------:|------:|-----:|--------:
|<u>Date</u>  |       |       |       |       |       |      |(b~i~)
|             |       |       |       |       |       |      |
|1            |-2.190 | 0.600 |-1.310 | -0.600| 1.290 |3.290 |2.64
|2            |-2.550 |-2.550 |-1.660 |1.660  |7.270  |3.840 |2.65
|3            |-2.140 |-2.140 |-0.740 |0.740  |5.000  |2.040 |2.39
|4            |-2.200 |-2.230 |-1.370 |1.370  |5.590  |3.950 |2.29
|5            |-2.685 |-2.675 |-0.665 |0.665  |5.985  |2.555 |2.84
|6            |-3.430 |-3.210 |0.700  |-0.690 |1.900  |0.690 |3.60


Next the median of the row medians (2.64) is computed as the first estimate of the overall median m. This is subtracted from each of the row medians:



|   Station:  | 1     |  2    | 3     |   4   | 5     |  6   |row med  
|-------------|----- :|------:|------:|------:|------:|-----:|--------:
|<u>Date</u>  |       |       |       |       |       |      |(b~i~)
|             |       |       |       |       |       |      |
|1            |-2.19  | 0.60  |-1.31  | -0.60 |1.29   |3.29  |0.00
|2            |-2.55  |-2.55  |-1.66  |1.66   |7.27   |3.84  |0.01
|3            |-2.14  |-2.14  |-0.74  |0.74   |5.00   |2.04  |-0.25
|4            |-2.20  |-2.23  |-1.37  |1.37   |5.59   |3.95  |-0.35
|5            |-2.69  |-2.67  |-0.67  |0.67   |5.98   |2.55  |0.20
|6            |-3.43  |-3.21  |0.70   |-0.69  |1.90   |0.69  |0.96
|             |       |       |       |       |       |      |m = **2.64**  

The median of each column (station) is then computed and subtracted from that column's data. The residuals from the subtractions remain in the table   


|   Station:  | 1     |  2    | 3     |   4   | 5     |  6   |row med  
|-------------|----- :|------:|------:|------:|------:|-----:|--------:
|<u>Date</u>  |       |       |       |       |       |      |(b~i~)
|             |       |       |       |       |       |      |
|1            | 0.19  | 2.99  |-0.29  |-1.31  |-4.01  |0.37  |0.00
|2            |-0.17  |-0.16  |-0.64  | 0.95  | 1.97  |0.92  |0.01
|3            | 0.24  | 0.25  | 0.28  | 0.03  |-0.30  |-0.88 |-0.25
|4            | 0.18  | 0.16  |-0.35  | 0.66  | 0.29  |1.03  |-0.35
|5            |-0.31  |-0.29  | 0.35  |-0.04  | 0.69  |-0.36 |0.20
|6            |-1.05  |-0.82  | 1.72  |-1.40  |-3.40  |-2.23 |0.96
|-------------|-------|-------|-------|-------|-------|------|---------  
|a~j~ col med:|-2.38  |-2.39  | -1.02 | 0.71  | 5.30  | 2.92 |m = **2.64**
-----------------------------------------------------------------------   

Then the median of the column medians (-0.16) is subtracted from each of the column medians,
and added to the overall median:   

|   Station:  | 1     |  2    | 3     |   4   | 5     |  6   |row med  
|-------------|----- :|------:|------:|------:|------:|-----:|--------:
|<u>Date</u>  |       |       |       |       |       |      |(b~i~)
|             |       |       |       |       |       |      |
|1            | 0.19  | 2.99  |-0.29  |-1.31  |-4.01  |0.37  |0.00
|2            |-0.17  |-0.16  |-0.64  | 0.95  | 1.97  |0.92  |0.01
|3            | 0.24  | 0.25  | 0.28  | 0.03  |-0.30  |-0.88 |-0.25
|4            | 0.18  | 0.16  |-0.35  | 0.66  | 0.29  |1.03  |-0.35
|5            |-0.31  |-0.29  | 0.35  |-0.04  | 0.69  |-0.36 |0.20
|6            |-1.05  |-0.82  | 1.72  |-1.40  |-3.40  |-2.23 |0.96
|-------------|-------|-------|-------|-------|-------|------|---------  
|a~j~ col med:|-2.22  |-2.23  | -0.86 | 0.87  | 5.46  | 3.08 |m = **2.48**
-----------------------------------------------------------------------  


This table now exhibits the first "polish" of the data. Usually two complete polishes are performed in order to produce more stable estimates of the overall median and row and column
effects. For the second polish, the above process is repeated on the table of residuals from the first polish. After a second complete polish, little change in the estimates is expected from further polishing. The table then looks like:   


|   Station:  | 1     |  2    | 3     |   4   | 5     |  6   |row med  
|-------------|----- :|------:|------:|------:|------:|-----:|--------:
|<u>Date</u>  |       |       |       |       |       |      |(b~i~)
|             |       |       |       |       |       |      |
|1            | 0.22  | 3.02  |-0.19  |-1.26  |-3.77  | 0.31 | 0.03
|2            |-0.57  |-0.56  |-0.97  | 0.57  | 1.78  | 0.43 | 0.47
|3            | 0.08  | 0.09  | 0.19  |-0.11  |-0.24  |-1.12 |-0.03
|4            |-0.08  |-0.09  |-0.54  | 0.42  | 0.24  | 0.69 |-0.03
|5            |-0.17  |-0.14  | 0.56  | 0.11  | 1.04  |-0.31 | 0.12
|6            | 1.05  | 0.38  | 2.99  |-0.18  |-1.98  |-1.11 |-0.18
|-------------|-------|-------|-------|-------|-------|------|---------  
|a~j~ col med:|-2.18  |-2.19  | -0.89 | 0.89  | 5.29  | 3.20 |m = **2.38**
-----------------------------------------------------------------------      

The above table shows that   
1) The station effects are large in comparison to the date effects (the a~j~ are much larger in absolute magnitude than the b~i~ ).   
2) There is a clear progression from smaller to larger values going downstream (a~j~ generally increases from stations 1 to 6), with the maximum at station 5.  3) A large residual occurs for station 5 at date 1 (smaller concentration than expected).   

#### Plots related to median polish for checking assumptions Median polish can be used to check the assumptions behind an analysis of variance. The first
assumption is that the residuals εij are normally distributed. Boxplots of the residuals eij in the table provide a look at the distribution of errors after the treatment and block effects have been removed. Figure \@ref(fig:fig-7-11) shows that for the periphyton mercury data the residuals are probably not normal due to the large proportion of outliers, but at least are relatively symmetric:   


```{r fig-7-11, echo = FALSE, fig.align='center', fig.cap=" Residuals from the median smooth of periphyton mercury data "} 
knitr::include_graphics("figures/7_11.png")

```


In addition, the additivity of the table can be checked. An ANOVA assumes that the treatment and block effects are additive. In other words, if being in group 1 adds -2.18 units of concentration to the overall mean or median, and if being at time 1 adds 0.03 units, these add together for treatment group 1 at time 1. If this is not the case, a transformation of the data prior to ANOVA must be performed to produce additivity. To check additivity, the "comparison value" c~ij~ (@hoaglin_understanding_1983) is computed for each combination ij of block and treatment group, where  

  c~ij~ = a~i~ • b~j~ / m .  
    
A residuals plot of the tabled residuals eij versus cij will appear to have a random scatter around
0 if the data are additive. If not, the pattern of residuals will lead to an appropriate transformation to additivity -- for a nonzero slope s, the data should be raised to the (1−s) power in the ladder of powers. In figure 7.12, a residuals plot for the mercury median polish indicate no clear nonzero slope (most of the data are clustered in a central cloud), and therefore no transformation is necessary.

```{r fig-7-12, echo = FALSE, fig.align='center', fig.cap=" Median polish residuals plot showing random scatter around e~ij~=0 "} 
knitr::include_graphics("figures/7_12.png")

```


### The Friedman Test  
The Friedman test is the most common nonparametric test used for the randomized complete block design. It computes the ranks of the data only within each block, not making crosscomparisons between blocks. Treatment effects are determined from the within-block ranks each treatment has received. The Friedman test is an extension of the sign test, and reduces to the sign test when comparing only two treatment groups. Its advantages and disadvantages in comparison to the analysis of variance are the same as that of the sign test to the t-test. When the errors εij can be considered normal, the ANOVA should be preferred. For the many situations where the errors are not normal, the Friedman test will generally have equal or greater power to detect differences between treatment groups, and should be performed. The Friedman test is especially useful when the data can be ranked but differences between observations cannot be computed, such as when comparing a <1 to a 5.  

#### Null and alternate hypotheses  
The Friedman test is used to determine whether   
  H~0~: the median values for k groups of data are identical, or
  H~1~: at least one median is significantly different.
As with the Kruskal-Wallis test, the test does not provide information on which medians are significantly different from others. That information must come from a multiple comparison test.  

#### Computation of the exact test  
Rank the data within each block from 1 to k, from smallest to largest. If the null hypothesis is true, the ranks within each block will vary randomly with no consistent pattern. Summing across blocks, the average rank for each treatment group will be similar for all groups, and also be close to the overall average rank. When the alternative hypothesis is true, the ranks in most of the blocks for one or more of the groups will be consistently higher or lower than others. The average group rank for those groups will then differ from the overall average rank. A test statistic Xf is constructed which uses the square of the differences between the average group ranks and the overall rank, to determine if groups differ in magnitude.  

The exact test statistic for the Friedman test is a function of both the number of blocks and treatments. @iman1980approximations state that the exact test should be used for all cases where the number of treatment groups plus the number of blocks (k + n) is ≤ 9. For larger sample sizes a large sample approximation is sufficiently accurate for use. When the number of blocks n is small, the F approximation should be preferred over the chi-square approximation (see the next section).  

Should the exact test be required, compute the exact test statistic Xf as shown for the large sample approximation of the following section. Xf is computed identically for both the exact form and large sample approximation. When ties occur, either a corrected large sample approximation must be used, or the rank transform (F approximation) calculated. The rank transform may be easier to compute 

#### Large sample approximation  
For years the Friedman test statistic was approximated using a chi-square distribution with k−1 degrees of freedom. This is the approximation used by statistics packages, and is presented here because of its common use. However, it does not take into account the number of blocks in the data set, and can be in serious error for small n and small α (α < 0.1) ((Iman and Davenport, (@iman1980approximations). An F approximation which is more accurate for small n is also available. It can be computed from the chi-square approximation, or directly from the data as a rank transform method (an analysis of variance on the within-block ranks R~ij~).  

The box on the next page outlines the computation process for the large sample approximation
to the Friedman test statistic.  

<u>Example 3, continued</u>.  
The Friedman test is used to determine if the median concentration of periphyton mercury differs for the 6 stations along the South River of Virginia. The boxplots of this data were shown in figure \@ref(fig:fig-7-10), and the data given in table 7.3. The within-block ranks are given below. For 6 blocks (date) and 6 stations, sample sizes are large enough to employ an approximation, so the preferred F approximation is computed.


Table 7.5 Within-Block Ranks of the Table 7.3 data **Here**
